{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ed7f0f",
   "metadata": {},
   "source": [
    "## 整合：從輸入到輸出 (課堂練習)\n",
    "\n",
    "`read_for_me` 函式整合了 S2T、LLM 修正、TTS 聲音複製的完整流程。\n",
    "請依照 `FIXME` 的指示，完成函式中缺少的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7340e7ec",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def read_for_me(\n",
    "    s2t_model: AutomaticSpeechRecognitionPipeline,\n",
    "    llm_model: TextGenerationPipeline,\n",
    "    transcripts_dict: dict, # 改為必要參數\n",
    "    input_text: str | None = None,\n",
    "    input_audio_path: str | None = None,\n",
    "    voice_to_clone_key: str = \"spongebob.wav\", # 預設模仿海綿寶寶\n",
    "    output_file: str = \"final_output.wav\",\n",
    "    output_dir: str = \"tts_final\"\n",
    "):\n",
    "    \"\"\"\n",
    "    整合 S2T -> LLM -> TTS 的流程。\n",
    "    (課堂練習：完成 FIXME 部分)\n",
    "    \"\"\"\n",
    "    # --- 1. 檢查與取得輸入文字 ---\n",
    "    if not input_text and not input_audio_path:\n",
    "        raise ValueError(\"必須提供 input_text 或 input_audio_path。\")\n",
    "    if input_text and input_audio_path:\n",
    "        raise ValueError(\"input_text 和 input_audio_path 不能同時提供。\")\n",
    "    if voice_to_clone_key not in transcripts_dict:\n",
    "        print(f\"警告：在文字稿字典中找不到 key '{voice_to_clone_key}'。\")\n",
    "\n",
    "    original_text = \"\"\n",
    "    if input_audio_path:\n",
    "        print(f\"步驟 1: S2T ({input_audio_path})\")\n",
    "        audio_file = Path(input_audio_path)\n",
    "        if not audio_file.exists(): raise FileNotFoundError(f\"找不到音檔: {input_audio_path}\")\n",
    "\n",
    "        # FIXME 1: 語音轉文字\n",
    "        # 提示：使用 s2t_model 這個 pipeline 來處理聲音檔案。\n",
    "        #      你需要將聲音檔案的路徑 (字串格式，例如 str(audio_file)) 傳遞給 s2t_model。\n",
    "        #      s2t_model 會回傳一個字典，辨識出的文字在 'text' 這個 key 裡面。\n",
    "        #      將辨識出的文字存到 original_text 變數中。\n",
    "        # s2t_result = s2t_model( ... ) # 填入正確的參數\n",
    "        # original_text = s2t_result[ ... ] # 取得 'text'\n",
    "        original_text = \"FIXME: 語音轉文字結果應存於此\" # <--- 請將這一行取代為你的程式碼\n",
    "\n",
    "        print(f\"  >> S2T 結果: {original_text}\")\n",
    "    else:\n",
    "        original_text = input_text\n",
    "        print(f\"步驟 1: 使用提供的文字: {original_text}\")\n",
    "\n",
    "    # --- 2. LLM 文法修正 ---\n",
    "    print(\"\\n步驟 2: LLM 文法修正\")\n",
    "    # 準備 LLM 輸入訊息 (這部分已完成)\n",
    "    messages = prepare_grammar_correction_messages(original_text)\n",
    "\n",
    "    # FIXME 2: 呼叫 LLM 進行修正\n",
    "    # 提示：使用 llm_model 這個 pipeline 來處理 messages。\n",
    "    #      記得設定 return_full_text=False 只取得模型生成的回應。\n",
    "    #      也可以設定 max_new_tokens (例如 len(original_text) + 50) 來限制輸出長度。\n",
    "    #      llm_model 會回傳一個列表，取第一個元素 (索引為 0) 的字典，\n",
    "    #      其中 'generated_text' key 的值就是修正後的文字。\n",
    "    #      將修正後的文字存到 corrected_text 變數中，並移除前後多餘的空白。\n",
    "    # llm_result = llm_model( ... , return_full_text=False, max_new_tokens=...) # 填入 messages 和其他參數\n",
    "    # corrected_text = llm_result[0][ ... ].strip() # 取得 'generated_text' 並清理\n",
    "    corrected_text = \"FIXME: 文法修正結果應存於此\" # <--- 請將這一行取代為你的程式碼\n",
    "\n",
    "    # 清理常見的模型輸出問題 (例如多餘的引號或標籤)\n",
    "    corrected_text = corrected_text.replace(\"```\", \"\").replace(\"`\", \"\").strip('\"').strip()\n",
    "    print(f\"  >> 修正後文字: {corrected_text}\")\n",
    "\n",
    "    # --- 3. TTS 聲音複製 ---\n",
    "    print(f\"\\n步驟 3: TTS 聲音複製 (模仿 {voice_to_clone_key})\")\n",
    "    # 取得參考聲音的路徑和文字稿 (這部分已完成)\n",
    "    # 修正：正確從 transcripts_dict 取得 transcription\n",
    "    voice_info = transcripts_dict.get(voice_to_clone_key, {})\n",
    "    voice_ref_text = voice_info.get(\"transcription\", \"\") # 安全取得文字稿\n",
    "    voice_ref_path_str = f\"./week9/{voice_to_clone_key}\"\n",
    "    voice_ref_path = Path(voice_ref_path_str)\n",
    "\n",
    "    if not voice_ref_path.exists():\n",
    "        raise FileNotFoundError(f\"找不到參考聲音檔: {voice_ref_path_str}\")\n",
    "    if not voice_ref_text:\n",
    "         print(\"(警告：找不到參考聲音文字稿，ref_text 將為空)\")\n",
    "\n",
    "    # FIXME 3: 呼叫聲音複製函式\n",
    "    # 提示：呼叫我們之前定義的 clone_voice 函式。\n",
    "    #      需要傳遞以下參數：\n",
    "    #      - path_to_ref_audio: 參考聲音檔案的路徑 (字串格式，這裡是 voice_ref_path)\n",
    "    #      - gen_text: 要轉換成語音的文字 (這裡是用 LLM 修正過的 corrected_text)\n",
    "    #      - ref_text: 參考聲音的文字稿 (這裡是 voice_ref_text)\n",
    "    #      - output_file: 輸出的檔名 (函式參數 output_file)\n",
    "    #      - output_dir: 輸出的目錄 (函式參數 output_dir)\n",
    "    # clone_voice(\n",
    "    #     path_to_ref_audio=str(voice_ref_path),\n",
    "    #     gen_text= ... , # 填入修正後的文字\n",
    "    #     ref_text= ... , # 填入參考文字稿\n",
    "    #     output_file= ... , # 填入輸出檔名\n",
    "    #     output_dir= ...   # 填入輸出目錄\n",
    "    # )\n",
    "    print(\"FIXME: 應在此處呼叫 clone_voice 函式\") # <--- 請將這一行取代為你的程式碼\n",
    "\n",
    "    # 修正：補上結尾括號\n",
    "    print(f\"\\n流程完成！最終語音預計儲存至 {Path(output_dir) / output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33575ec",
   "metadata": {},
   "source": [
    "### 執行整合流程 (練習用)\n",
    "\n",
    "在完成上面的 `FIXME` 部分後，執行此區塊來測試你的 `read_for_me` 函式。\n",
    "範例 1 使用文字輸入，範例 2 嘗試使用之前錄製的聲音檔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe372e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 執行整合流程 - 範例 1: 文字輸入，川普聲音 (依照你的範例修改)\n",
    "print(\"--- 執行整合流程：範例 1 (文字輸入) ---\")\n",
    "try:\n",
    "    # 確保 transcripts 字典已載入\n",
    "    if not transcripts:\n",
    "         print(\"錯誤：transcripts 字典是空的，無法執行。請先確認文字稿檔案已成功載入。\")\n",
    "    else:\n",
    "        read_for_me(\n",
    "            s2t_model=s2t,\n",
    "            llm_model=llm,\n",
    "            transcripts_dict=transcripts, # 傳入文字稿字典\n",
    "            input_text=\"i has a apple.\", # 簡單錯誤英文\n",
    "            voice_to_clone_key=\"trump.wav\", # 改為模仿川普\n",
    "            output_file=\"trump_corrected_apple_exercise.wav\" # 改個檔名避免覆蓋\n",
    "        )\n",
    "except NameError as e:\n",
    "    print(f\"執行範例 1 時發生錯誤：似乎有變數未定義 ({e})。請檢查 FIXME 部分是否都已完成。\")\n",
    "except FileNotFoundError as e:\n",
    "     print(f\"執行範例 1 時發生錯誤：找不到檔案 ({e})。請確認參考聲音檔存在。\")\n",
    "except Exception as e:\n",
    "    print(f\"執行範例 1 時發生預期外的錯誤: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "# 執行整合流程 - 範例 2: 聲音輸入 (若存在)，海綿寶寶聲音 (範例2改回海綿寶寶)\n",
    "print(\"--- 執行整合流程：範例 2 (聲音輸入) ---\")\n",
    "my_recording_wav_path = \"my_recording.wav\" # 假設已轉換成 WAV\n",
    "my_recording_webm_path = \"my_recording.webm\" # 或者使用 webm\n",
    "\n",
    "input_audio_for_test = None\n",
    "if Path(my_recording_wav_path).exists():\n",
    "    input_audio_for_test = my_recording_wav_path\n",
    "elif Path(my_recording_webm_path).exists():\n",
    "     input_audio_for_test = my_recording_webm_path # Whisper 通常能處理 webm\n",
    "\n",
    "if input_audio_for_test:\n",
    "    print(f\"使用錄音檔: {input_audio_for_test}\")\n",
    "    try:\n",
    "        # 確保 transcripts 字典已載入\n",
    "        if not transcripts:\n",
    "            print(\"錯誤：transcripts 字典是空的，無法執行。請先確認文字稿檔案已成功載入。\")\n",
    "        else:\n",
    "            read_for_me(\n",
    "                s2t_model=s2t,\n",
    "                llm_model=llm,\n",
    "                transcripts_dict=transcripts,\n",
    "                input_audio_path=input_audio_for_test, # 使用錄音檔\n",
    "                voice_to_clone_key=\"spongebob.wav\",     # 模仿海綿寶寶\n",
    "                output_file=\"my_recording_spongebob_voice_exercise.wav\" # 改個檔名\n",
    "            )\n",
    "    except NameError as e:\n",
    "        print(f\"執行範例 2 時發生錯誤：似乎有變數未定義 ({e})。請檢查 FIXME 部分是否都已完成。\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"執行範例 2 時發生錯誤：找不到檔案 ({e})。請確認錄音檔和參考聲音檔都存在。\")\n",
    "    except Exception as e:\n",
    "        print(f\"執行範例 2 時發生預期外的錯誤: {e}\")\n",
    "else:\n",
    "    print(f\"找不到錄音檔 ({my_recording_wav_path} 或 {my_recording_webm_path})，跳過範例 2。\")\n",
    "    print(\"請確認已成功錄音並執行儲存步驟。\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
